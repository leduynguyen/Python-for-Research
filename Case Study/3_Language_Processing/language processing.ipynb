{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Language Processing\n",
    "In this case study, we will examine the properties of individual books in a book collection from various authors and various languages. More specifically, we will look at book lengths, number of unique words and how these attributes cluster by language of or authorship.\n",
    "\n",
    "A collection of over 100 titles from Project Gutenberg for analysis as a sample library for this case study. At the top level, we have four languages: English, French, German and Portuguese. For each language, we have from one to four authors each, 13 authors in total.\n",
    "\n",
    "Our goal is to write a function that given a string of text counts the number of times each unique word appears. What's the best way to keep track of these words? Python dictionaries are a very natural choice. Here, the keys are strings, the words containing the input text and the values are numbers that counts indicating how many times each word appears in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Words\n",
    "* Learn how to write your own function to count the number of times a unique word appears in a given string text\n",
    "* Learn about how to use the Counter tool from the collections module to accomplish the same task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'be': 1,\n",
       " 'do': 1,\n",
       " 'is': 1,\n",
       " 'it': 2,\n",
       " \"let's\": 1,\n",
       " 'string.': 1,\n",
       " 'test': 2,\n",
       " 'this': 1,\n",
       " 'to': 1,\n",
       " 'use': 1,\n",
       " 'will': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a test string. It will be use to test! Let's do it!\"\n",
    "\n",
    "def count_words(input_text):\n",
    "    \"\"\" Count the number of time each word occurs in text.\n",
    "    Return dictionary where keys are unique words & values are word count. \n",
    "    Skip the punctuation\"\"\"\n",
    "    \n",
    "    # Convert the text to lower case\n",
    "    input_text = input_text.lower()\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    skips = [\",\", \" . \", \"!\", \":\"]\n",
    "    for ch in skips:\n",
    "        input_text = input_text.replace(ch, \"\")\n",
    "    \n",
    "    # Init the dictionary for word counter\n",
    "    word_cnt = {}\n",
    "    \n",
    "    # Split & count the word by loop over the text\n",
    "    for word in input_text.split(\" \"):\n",
    "        if word in word_cnt:\n",
    "            word_cnt[word] += 1\n",
    "        else:\n",
    "            word_cnt[word] = 1\n",
    "    return word_cnt\n",
    "\n",
    "count_words(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is such a common operation that Python provides what is known as a counter tool to support rabbit tallies. We first need to import it from the collections module, which provides many additional high performance data types. The object returned by counter behaves much like a dictionary, although strictly speaking it's a subclass of the Python dictionary object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 1,\n",
       "         'be': 1,\n",
       "         'do': 1,\n",
       "         'is': 1,\n",
       "         'it': 2,\n",
       "         \"let's\": 1,\n",
       "         'string.': 1,\n",
       "         'test': 2,\n",
       "         'this': 1,\n",
       "         'to': 1,\n",
       "         'use': 1,\n",
       "         'will': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "text = \"This is a test string. It will be use to test! Let's do it!\"\n",
    "\n",
    "def count_words(input_text):\n",
    "    \"\"\" Count the number of time each word occurs in text.\n",
    "    Return dictionary where keys are unique words & values are word count. \n",
    "    Skip the punctuation\"\"\"\n",
    "    \n",
    "    # Convert the text to lower case\n",
    "    input_text = input_text.lower()\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    skips = [\",\", \" . \", \"!\", \":\"]\n",
    "    for ch in skips:\n",
    "        input_text = input_text.replace(ch, \"\")\n",
    "    \n",
    "    # Using the Counter from the collections\n",
    "    word_cnt = Counter(input_text.split(\" \"))\n",
    "    return word_cnt\n",
    "\n",
    "count_words(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a book from a file\n",
    "We're familiar by now with reading files. But here we'll include an additional argument. Character encoding refers to the process how computer encodes certain characters. In this case, we'll use what is called UTF-8 encoding, which is the dominant character encoding for the web, also replace backslash n and backslash r characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's in a name? That which we call a rose    By any other name would smell as sweet.    So Romeo w\n"
     ]
    }
   ],
   "source": [
    "def read_book(title_path):\n",
    "    \"\"\"Read a book and return a string\"\"\"\n",
    "    with open(title_path, \"r\", encoding=\"utf8\") as current_file:\n",
    "        text = current_file.read()\n",
    "        text = text.replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n",
    "    return text\n",
    "\n",
    "text =  read_book(\"./Books/English/shakespeare/Romeo and Juliet.txt\")\n",
    "ind = text.find(\"What's in a name?\")\n",
    "\n",
    "sample_text = text[ind:ind+100]\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word stats function\n",
    "Given a dictionary or a counter object from the collections module, we would like to know how many unique words there are in a given book. We'd also like to return the frequencies of each word, meaning, count-specifying how many times each word has appeared. To do this we'll be writing a word stats function. Our function is going to be called words stats, short for word statistics. And the input is going to be word counts, which is returned to us by the other function we previously wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in English version 5812\n",
      "Number of words in English version 40772\n",
      "Number of unique words in German version 7630\n",
      "Number of words in German version 20311\n"
     ]
    }
   ],
   "source": [
    "def count_words(input_text):\n",
    "    \"\"\" Count the number of time each word occurs in text.\n",
    "    Return dictionary where keys are unique words & values are word count. Skip the punctuation\"\"\"\n",
    "    # Convert the text to lower case\n",
    "    input_text = input_text.lower()\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    skips = [\",\", \" . \", \"!\", \":\"]\n",
    "    for ch in skips:\n",
    "        input_text = input_text.replace(ch, \"\")\n",
    "    \n",
    "    # Using the Counter from the collections\n",
    "    word_cnt = Counter(input_text.split(\" \"))\n",
    "    return word_cnt\n",
    "\n",
    "def read_book(title_path):\n",
    "    \"\"\"Read a book and return a string\"\"\"\n",
    "    with open(title_path, \"r\", encoding=\"utf8\") as current_file:\n",
    "        text = current_file.read()\n",
    "        text = text.replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n",
    "    return text\n",
    "\n",
    "def word_stats(word_counts):\n",
    "    \"\"\"Retunr number of unique words and words frequency\"\"\"\n",
    "    num_unique = len(word_counts)\n",
    "    counts = word_counts.values()\n",
    "    return (num_unique, counts)\n",
    "\n",
    "Eng_text =  read_book(\"./Books/English/shakespeare/Romeo and Juliet.txt\")\n",
    "Ger_text =  read_book(\"./Books/German/shakespeare/Romeo und Julia.txt\")\n",
    "\n",
    "Eng_word_cnt = count_words(Eng_text)\n",
    "Ger_word_cnt = count_words(Ger_text)\n",
    "\n",
    "(num_unique, counts) = word_stats(Eng_word_cnt)\n",
    "print(\"Number of unique words in English version\", num_unique)\n",
    "print(\"Number of words in English version\", sum(counts))\n",
    "\n",
    "(num_unique, counts) = word_stats(Ger_word_cnt)\n",
    "print(\"Number of unique words in German version\", num_unique)\n",
    "print(\"Number of words in German version\", sum(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
